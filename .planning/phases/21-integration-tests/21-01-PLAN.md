---
phase: 21-integration-tests
plan: 01
type: execute
---

<objective>
Integration tests for media plan pipeline stages verifying data flow between Extract, Research, Logic, and Synthesize stages with mocked AI responses.

Purpose: Verify pipeline orchestration correctly chains stage outputs and handles errors at each stage.
Output: Integration tests for all 4 pipeline stages with ~30-40 tests covering happy paths and error scenarios.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Prior phase summaries:**
@.planning/phases/19-test-infrastructure/19-01-SUMMARY.md
@.planning/phases/19-test-infrastructure/19-02-SUMMARY.md
@.planning/phases/20-unit-tests-core/20-01-SUMMARY.md

**Codebase constraints:**
- Vitest 4.0 with jsdom environment (from Phase 19)
- MockOpenRouterClient for AI response mocking
- AAA pattern (Arrange-Act-Assert) for test structure
- vi.mock() for module mocking

**Source files:**
@src/lib/media-plan/pipeline/index.ts
@src/lib/media-plan/pipeline/extract.ts
@src/lib/media-plan/pipeline/research.ts
@src/lib/media-plan/pipeline/logic.ts
@src/lib/media-plan/pipeline/synthesize.ts
@src/test/mocks/openrouter.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Pipeline orchestrator integration tests</name>
  <files>src/lib/media-plan/pipeline/__tests__/pipeline.integration.test.ts</files>
  <action>
Create integration tests for runMediaPlanPipeline() that verify:
1. Happy path: All 4 stages complete successfully with mocked responses
2. Progress callback receives correct stage transitions (extract → research → logic → synthesize → complete)
3. Abort signal cancels pipeline mid-execution
4. Stage timing and cost aggregation in metadata
5. Error propagation: Each stage failure returns correct error message and failed stage

Mock strategy:
- Use vi.mock() to mock each stage module (extract.ts, research.ts, etc.)
- Create mock stage results with realistic data structures
- Use vi.fn() to track stage invocations and verify call order

Test structure:
- describe('runMediaPlanPipeline')
  - describe('successful execution')
  - describe('progress tracking')
  - describe('abort handling')
  - describe('error handling')
  </action>
  <verify>npm test src/lib/media-plan/pipeline/__tests__/pipeline.integration.test.ts passes</verify>
  <done>Pipeline orchestrator has ~15 integration tests covering orchestration, progress, abort, and errors</done>
</task>

<task type="auto">
  <name>Task 2: Individual stage integration tests</name>
  <files>src/lib/media-plan/pipeline/__tests__/stages.integration.test.ts</files>
  <action>
Create integration tests for each pipeline stage function:

1. runExtractStage tests:
   - Returns ExtractedData with correct structure from mocked Gemini response
   - Handles malformed JSON response gracefully
   - Tracks cost and duration in result

2. runResearchStage tests:
   - Receives ExtractedData, returns ResearchData
   - Includes citations from mocked Perplexity response
   - Handles empty research results

3. runLogicStage tests:
   - Receives ExtractedData + ResearchData
   - Returns LogicData with channel recommendations
   - Validates budget allocation logic

4. runSynthesizeStage tests:
   - Receives all prior stage data
   - Returns MediaPlanBlueprint with all 11 sections
   - Validates section structure matches Zod schemas

Mock approach:
- Mock OpenRouterClient at module level
- Queue specific JSON responses for each stage's expected output
- Verify each stage calls client with correct model (Gemini/Perplexity/GPT/Claude)
  </action>
  <verify>npm test src/lib/media-plan/pipeline/__tests__/stages.integration.test.ts passes</verify>
  <done>Each pipeline stage has ~5-6 tests verifying input/output contracts and error handling</done>
</task>

<task type="auto">
  <name>Task 3: Test data factories for pipeline types</name>
  <files>src/test/factories/media-plan.ts</files>
  <action>
Create factory functions for pipeline test data:

1. createMockNicheFormData(overrides?) - NicheFormData factory
2. createMockBriefingFormData(overrides?) - BriefingFormData factory
3. createMockExtractedData(overrides?) - ExtractedData factory
4. createMockResearchData(overrides?) - ResearchData factory
5. createMockLogicData(overrides?) - LogicData factory
6. createMockMediaPlanBlueprint(overrides?) - Full blueprint factory

Each factory should:
- Return valid data matching Zod schema requirements
- Accept partial overrides for customization
- Use realistic but deterministic test values

Export from src/test/index.ts barrel file.
  </action>
  <verify>Factories are exported and used in pipeline tests without type errors</verify>
  <done>6 factory functions created for pipeline test data, exported from test utilities</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm test -- --run` passes all tests (no regressions)
- [ ] Pipeline integration tests cover orchestration flow
- [ ] Stage integration tests verify input/output contracts
- [ ] Factories are reusable across test files
- [ ] No TypeScript errors
</verification>

<success_criteria>
- All tasks completed
- ~25-30 new integration tests for pipeline
- Test coverage for happy path and error scenarios
- Factory functions enable clean test setup
</success_criteria>

<output>
After completion, create `.planning/phases/21-integration-tests/21-01-SUMMARY.md`
</output>
