---
phase: 09-openrouter-multi-model
plan: 01
type: execute
---

<objective>
Extend OpenRouter client to support multi-model research pipeline with Perplexity, OpenAI o3, Gemini, and Claude Opus.

Purpose: Enable v1.3 multi-agent research by adding model definitions, pricing, and reasoning parameter support to the existing OpenRouter client.
Output: Updated client.ts with new models, costs, and reasoning capabilities ready for Phase 10's research agent infrastructure.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Codebase context:**
@.planning/codebase/INTEGRATIONS.md
@.planning/codebase/ARCHITECTURE.md

**Current implementation:**
@src/lib/openrouter/client.ts

**Discovery findings (Level 1 - Quick Verification):**

| Model | OpenRouter ID | Input $/M | Output $/M | Context | Special |
|-------|---------------|-----------|------------|---------|---------|
| Perplexity Sonar Pro | `perplexity/sonar-pro` | $3 | $15 | 200K | web_search_options |
| Perplexity Deep Research | `perplexity/sonar-deep-research` | $2 | $8 | 128K | reasoning, web_search_options |
| OpenAI o3-mini | `openai/o3-mini` | $1.10 | $4.40 | 200K | reasoning.effort (low/medium/high) |
| Gemini 2.5 Flash | `google/gemini-2.5-flash` | $0.30 | $2.50 | 1M | reasoning, include_reasoning |
| Claude Opus 4 | `anthropic/claude-opus-4` | $15 | $75 | 200K | reasoning.max_tokens |

**OpenRouter reasoning parameter patterns:**

1. **Effort-based** (OpenAI o1/o3, Grok): `reasoning: { effort: "low"|"medium"|"high" }`
2. **Token-based** (Anthropic, Gemini): `reasoning: { max_tokens: number }` (min 1024)
3. **Include reasoning in response**: `reasoning: { include: true }` or legacy `include_reasoning: true`

Sources:
- https://openrouter.ai/docs/guides/best-practices/reasoning-tokens
- https://openrouter.ai/openai/o3-mini
- https://openrouter.ai/perplexity/sonar-deep-research
- https://openrouter.ai/anthropic/claude-opus-4
- https://openrouter.ai/google/gemini-2.5-flash
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend MODELS constant and MODEL_COSTS</name>
  <files>src/lib/openrouter/client.ts</files>
  <action>
Add new model constants to MODELS object:
```typescript
export const MODELS = {
  // Existing models
  GEMINI_FLASH: "google/gemini-2.0-flash-001",
  PERPLEXITY_SONAR: "perplexity/sonar-pro",
  GPT_4O: "openai/gpt-4o",
  CLAUDE_SONNET: "anthropic/claude-sonnet-4",
  // New models for v1.3 multi-agent research
  PERPLEXITY_DEEP_RESEARCH: "perplexity/sonar-deep-research",
  O3_MINI: "openai/o3-mini",
  GEMINI_25_FLASH: "google/gemini-2.5-flash",
  CLAUDE_OPUS: "anthropic/claude-opus-4",
} as const;
```

Update MODEL_COSTS with accurate pricing from discovery (per 1M tokens):
```typescript
const MODEL_COSTS: Record<string, { input: number; output: number }> = {
  // Existing
  [MODELS.GEMINI_FLASH]: { input: 0.075, output: 0.30 },
  [MODELS.PERPLEXITY_SONAR]: { input: 3.0, output: 15.0 },
  [MODELS.GPT_4O]: { input: 2.5, output: 10.0 },
  [MODELS.CLAUDE_SONNET]: { input: 3.0, output: 15.0 },
  // New models
  [MODELS.PERPLEXITY_DEEP_RESEARCH]: { input: 2.0, output: 8.0 },
  [MODELS.O3_MINI]: { input: 1.10, output: 4.40 },
  [MODELS.GEMINI_25_FLASH]: { input: 0.30, output: 2.50 },
  [MODELS.CLAUDE_OPUS]: { input: 15.0, output: 75.0 },
};
```

Note: Perplexity models have additional $5/K search cost not tracked here - will be tracked separately in Phase 10's research agent.
  </action>
  <verify>TypeScript compiles without errors: `npx tsc --noEmit`</verify>
  <done>MODELS and MODEL_COSTS include all 8 models with correct IDs and pricing</done>
</task>

<task type="auto">
  <name>Task 2: Add reasoning parameter support to ChatCompletionOptions and chat()</name>
  <files>src/lib/openrouter/client.ts</files>
  <action>
1. Add ReasoningOptions type and extend ChatCompletionOptions:
```typescript
export type ReasoningEffort = "low" | "medium" | "high";

export interface ReasoningOptions {
  /** Effort level for OpenAI o-series models */
  effort?: ReasoningEffort;
  /** Max tokens for Anthropic/Gemini reasoning (min 1024) */
  maxTokens?: number;
  /** Include reasoning in response (default: false) */
  include?: boolean;
}

export interface ChatCompletionOptions {
  model: string;
  messages: ChatMessage[];
  temperature?: number;
  maxTokens?: number;
  jsonMode?: boolean;
  timeout?: number;
  /** Reasoning/thinking parameters for supported models */
  reasoning?: ReasoningOptions;
}
```

2. Update chat() method to include reasoning in requestBody when provided:
```typescript
// After existing requestBody setup...

// Add reasoning parameters if provided
if (options.reasoning) {
  const reasoningConfig: Record<string, unknown> = {};

  if (options.reasoning.effort) {
    // OpenAI o-series format
    reasoningConfig.effort = options.reasoning.effort;
  }
  if (options.reasoning.maxTokens) {
    // Anthropic/Gemini format (enforce minimum 1024)
    reasoningConfig.max_tokens = Math.max(1024, options.reasoning.maxTokens);
  }
  if (options.reasoning.include) {
    reasoningConfig.include = true;
  }

  if (Object.keys(reasoningConfig).length > 0) {
    requestBody.reasoning = reasoningConfig;
  }
}
```

Note: Do NOT modify chatJSON or chatJSONValidated - reasoning is a pass-through parameter for the raw chat() method.
  </action>
  <verify>TypeScript compiles without errors: `npx tsc --noEmit`</verify>
  <done>ChatCompletionOptions has optional reasoning field, chat() passes reasoning to OpenRouter API</done>
</task>

<task type="auto">
  <name>Task 3: Add model capability helpers and update exports</name>
  <files>src/lib/openrouter/client.ts</files>
  <action>
1. Add helper to check if model supports reasoning:
```typescript
/** Models that support reasoning/thinking parameters */
const REASONING_MODELS = new Set([
  MODELS.O3_MINI,
  MODELS.GEMINI_25_FLASH,
  MODELS.CLAUDE_OPUS,
  MODELS.PERPLEXITY_DEEP_RESEARCH,
]);

export function supportsReasoning(model: string): boolean {
  return REASONING_MODELS.has(model);
}
```

2. Add helper for models with web search capability (for Phase 10):
```typescript
/** Models that include web search/citations */
const WEB_SEARCH_MODELS = new Set([
  MODELS.PERPLEXITY_SONAR,
  MODELS.PERPLEXITY_DEEP_RESEARCH,
]);

export function hasWebSearch(model: string): boolean {
  return WEB_SEARCH_MODELS.has(model);
}
```

3. Export ReasoningOptions and ReasoningEffort types (already in module scope via export).

4. Add JSDoc to MODELS constant documenting use cases:
```typescript
/**
 * Model identifiers for OpenRouter
 *
 * Research/Search models:
 * - PERPLEXITY_SONAR: Real-time web search, citations
 * - PERPLEXITY_DEEP_RESEARCH: Multi-step research with reasoning
 *
 * Reasoning models:
 * - O3_MINI: Cost-efficient STEM reasoning
 * - GEMINI_25_FLASH: Fast reasoning with 1M context
 * - CLAUDE_OPUS: Deep reasoning for complex tasks
 *
 * General purpose:
 * - GEMINI_FLASH: Fast extraction and simple tasks
 * - GPT_4O: Balanced capability
 * - CLAUDE_SONNET: Synthesis and writing
 */
export const MODELS = { ... } as const;
```
  </action>
  <verify>
1. TypeScript compiles: `npx tsc --noEmit`
2. Verify exports are accessible: Create a test import in a scratch file or check via IDE
  </verify>
  <done>Helper functions exported, MODELS documented, all types exported for Phase 10 consumption</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `npx tsc --noEmit` passes with no errors
- [ ] `npm run build` succeeds
- [ ] MODELS constant has 8 models (4 existing + 4 new)
- [ ] MODEL_COSTS has pricing for all 8 models
- [ ] ChatCompletionOptions includes optional reasoning field
- [ ] chat() method passes reasoning to API when provided
- [ ] supportsReasoning() and hasWebSearch() helpers exported
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- No TypeScript errors
- OpenRouter client ready for Phase 10 research agent infrastructure
</success_criteria>

<output>
After completion, create `.planning/phases/09-openrouter-multi-model/09-01-SUMMARY.md`:

# Phase 9 Plan 1: OpenRouter Multi-Model Support Summary

**[Substantive one-liner describing what shipped]**

## Accomplishments

- [Key outcomes]

## Files Created/Modified

- `src/lib/openrouter/client.ts` - Description of changes

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Step

Ready for Phase 10: Research Agent Infrastructure
</output>
