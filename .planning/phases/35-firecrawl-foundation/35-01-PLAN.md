---
phase: 35-firecrawl-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/firecrawl/types.ts
  - src/lib/firecrawl/client.ts
  - src/lib/firecrawl/index.ts
  - src/lib/env.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "FirecrawlClient can scrape a URL and return markdown"
    - "Missing FIRECRAWL_API_KEY does not crash the application"
    - "Scraping errors are logged and handled gracefully"
  artifacts:
    - path: "src/lib/firecrawl/types.ts"
      provides: "Type definitions for Firecrawl scraping"
      exports: ["ScrapeOptions", "ScrapeResult", "PricingPageResult"]
    - path: "src/lib/firecrawl/client.ts"
      provides: "Firecrawl SDK wrapper with AI-GOS patterns"
      exports: ["FirecrawlClient", "createFirecrawlClient"]
    - path: "src/lib/firecrawl/index.ts"
      provides: "Barrel export for firecrawl module"
      exports: ["FirecrawlClient", "createFirecrawlClient"]
  key_links:
    - from: "src/lib/firecrawl/client.ts"
      to: "src/lib/env.ts"
      via: "getEnv for optional FIRECRAWL_API_KEY"
      pattern: "getEnv.*FIRECRAWL_API_KEY"
---

<objective>
Create FirecrawlClient service that wraps @mendable/firecrawl-js SDK with AI-GOS error handling patterns.

Purpose: Provide the foundation layer for pricing page scraping. Phase 36 will use this client to extract structured pricing data via LLM.

Output: Working FirecrawlClient that scrapes URLs returning clean markdown, with graceful degradation when API key is missing.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/35-firecrawl-foundation/35-CONTEXT.md
@.planning/research/SUMMARY.md
@src/lib/env.ts
@src/lib/ad-library/types.ts
@src/lib/ad-library/service.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Firecrawl SDK and create types</name>
  <files>package.json, src/lib/firecrawl/types.ts</files>
  <action>
1. Install the Firecrawl SDK:
   ```bash
   npm install @mendable/firecrawl-js
   ```

2. Create `src/lib/firecrawl/types.ts` with type definitions:

```typescript
// Firecrawl Types and Interfaces
// Types for pricing page scraping via Firecrawl SDK

/**
 * Options for scraping a single URL
 */
export interface ScrapeOptions {
  /** URL to scrape */
  url: string;
  /** Timeout in milliseconds (default: 30000) */
  timeout?: number;
  /** Whether to wait for JavaScript rendering (default: true) */
  waitForJs?: boolean;
}

/**
 * Result of scraping a single URL
 */
export interface ScrapeResult {
  /** Whether the scrape succeeded */
  success: boolean;
  /** Scraped content as markdown (undefined if failed) */
  markdown?: string;
  /** Page title if available */
  title?: string;
  /** Page URL (may differ from input if redirected) */
  url?: string;
  /** Error message if failed */
  error?: string;
  /** HTTP status code if available */
  statusCode?: number;
}

/**
 * Result of attempting to find and scrape a pricing page
 */
export interface PricingPageResult {
  /** Whether a pricing page was found and scraped */
  found: boolean;
  /** The URL that successfully returned content */
  url?: string;
  /** Scraped markdown content */
  markdown?: string;
  /** Page title if available */
  title?: string;
  /** Error message if all attempts failed */
  error?: string;
  /** URLs that were attempted */
  attemptedUrls: string[];
}

/**
 * Options for batch scraping multiple URLs
 */
export interface BatchScrapeOptions {
  /** URLs to scrape */
  urls: string[];
  /** Timeout per URL in milliseconds (default: 30000) */
  timeout?: number;
}

/**
 * Result of batch scraping
 */
export interface BatchScrapeResult {
  /** Individual results keyed by URL */
  results: Map<string, ScrapeResult>;
  /** Number of successful scrapes */
  successCount: number;
  /** Number of failed scrapes */
  failureCount: number;
}
```

Follow the pattern from `src/lib/ad-library/types.ts` for documentation style.
  </action>
  <verify>
- `npm install` completes without error
- `npm run lint` passes
- TypeScript compiles: `npx tsc --noEmit`
  </verify>
  <done>
- @mendable/firecrawl-js appears in package.json dependencies
- src/lib/firecrawl/types.ts exists with all type exports
  </done>
</task>

<task type="auto">
  <name>Task 2: Create FirecrawlClient with graceful degradation</name>
  <files>src/lib/firecrawl/client.ts, src/lib/env.ts</files>
  <action>
1. Update `src/lib/env.ts` to add FIRECRAWL_API_KEY as optional:

Add to OPTIONAL_ENV_VARS.server array:
```typescript
server: [
  "FOREPLAY_API_KEY",
  "ENABLE_FOREPLAY",
  "FIRECRAWL_API_KEY",  // ADD THIS
] as const,
```

2. Create `src/lib/firecrawl/client.ts`:

```typescript
// Firecrawl Client
// Wraps @mendable/firecrawl-js SDK with AI-GOS error handling patterns

import Firecrawl from '@mendable/firecrawl-js';
import { getEnv, hasEnv } from '@/lib/env';
import type {
  ScrapeOptions,
  ScrapeResult,
  PricingPageResult,
  BatchScrapeOptions,
  BatchScrapeResult,
} from './types';

const DEFAULT_TIMEOUT = 30000; // 30 seconds
const PRICING_PATHS = ['/pricing', '/plans', '/buy'] as const;

/**
 * Firecrawl client for scraping web pages with JavaScript rendering
 *
 * Graceful degradation: If FIRECRAWL_API_KEY is not set, all methods
 * return failure results without throwing. Callers should check
 * isAvailable() before making requests if they need to know upfront.
 */
export class FirecrawlClient {
  private client: Firecrawl | null = null;
  private readonly apiKey: string | undefined;

  constructor() {
    this.apiKey = getEnv('FIRECRAWL_API_KEY');
    if (this.apiKey) {
      this.client = new Firecrawl({ apiKey: this.apiKey });
    }
  }

  /**
   * Check if Firecrawl is available (API key is configured)
   */
  isAvailable(): boolean {
    return this.client !== null;
  }

  /**
   * Scrape a single URL and return markdown content
   *
   * @param options - Scrape options including URL and timeout
   * @returns ScrapeResult with markdown or error
   */
  async scrape(options: ScrapeOptions): Promise<ScrapeResult> {
    if (!this.client) {
      return {
        success: false,
        error: 'Firecrawl not available: FIRECRAWL_API_KEY not configured',
      };
    }

    const timeout = options.timeout ?? DEFAULT_TIMEOUT;

    try {
      // Create abort controller for timeout
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);

      const response = await this.client.scrapeUrl(options.url, {
        formats: ['markdown'],
      });

      clearTimeout(timeoutId);

      if (!response.success) {
        console.warn(`[Firecrawl] Scrape failed for ${options.url}:`, response);
        return {
          success: false,
          url: options.url,
          error: 'Scrape failed - no content returned',
        };
      }

      // Extract markdown from response
      const markdown = response.markdown;
      if (!markdown || markdown.trim().length === 0) {
        return {
          success: false,
          url: options.url,
          error: 'Scrape returned empty content',
        };
      }

      // Warn if content seems too short (possible JS rendering issue)
      const wordCount = markdown.split(/\s+/).length;
      if (wordCount < 100) {
        console.warn(
          `[Firecrawl] Low word count (${wordCount}) for ${options.url} - may indicate rendering issue`
        );
      }

      return {
        success: true,
        markdown,
        title: response.metadata?.title,
        url: response.metadata?.sourceURL ?? options.url,
        statusCode: response.metadata?.statusCode,
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);

      // Check for specific error types
      if (errorMessage.includes('abort') || errorMessage.includes('timeout')) {
        console.error(`[Firecrawl] Timeout scraping ${options.url} after ${timeout}ms`);
        return {
          success: false,
          url: options.url,
          error: `Request timed out after ${timeout}ms`,
        };
      }

      console.error(`[Firecrawl] Error scraping ${options.url}:`, errorMessage);
      return {
        success: false,
        url: options.url,
        error: errorMessage,
      };
    }
  }

  /**
   * Find and scrape a pricing page for a given website
   *
   * Tries common pricing page paths in order: /pricing, /plans, /buy
   * Returns the first successful result or error if all fail.
   *
   * @param websiteUrl - Base website URL (e.g., https://example.com)
   * @returns PricingPageResult with markdown or error
   */
  async scrapePricingPage(websiteUrl: string): Promise<PricingPageResult> {
    if (!this.client) {
      return {
        found: false,
        error: 'Firecrawl not available: FIRECRAWL_API_KEY not configured',
        attemptedUrls: [],
      };
    }

    // Normalize base URL
    const baseUrl = this.normalizeBaseUrl(websiteUrl);
    const attemptedUrls: string[] = [];

    for (const path of PRICING_PATHS) {
      const url = `${baseUrl}${path}`;
      attemptedUrls.push(url);

      console.log(`[Firecrawl] Trying pricing page: ${url}`);

      const result = await this.scrape({ url });

      if (result.success && result.markdown) {
        console.log(`[Firecrawl] Found pricing page: ${url} (${result.markdown.length} chars)`);
        return {
          found: true,
          url: result.url ?? url,
          markdown: result.markdown,
          title: result.title,
          attemptedUrls,
        };
      }

      // Log specific failure for debugging
      console.log(`[Firecrawl] ${path} failed: ${result.error ?? 'unknown error'}`);
    }

    // All paths failed
    console.warn(`[Firecrawl] No pricing page found for ${baseUrl}`);
    return {
      found: false,
      error: `No pricing page found. Tried: ${PRICING_PATHS.join(', ')}`,
      attemptedUrls,
    };
  }

  /**
   * Scrape multiple URLs in batch (parallel execution)
   *
   * @param options - Batch scrape options
   * @returns BatchScrapeResult with individual results
   */
  async batchScrape(options: BatchScrapeOptions): Promise<BatchScrapeResult> {
    if (!this.client) {
      const results = new Map<string, ScrapeResult>();
      for (const url of options.urls) {
        results.set(url, {
          success: false,
          error: 'Firecrawl not available: FIRECRAWL_API_KEY not configured',
        });
      }
      return {
        results,
        successCount: 0,
        failureCount: options.urls.length,
      };
    }

    const timeout = options.timeout ?? DEFAULT_TIMEOUT;
    const results = new Map<string, ScrapeResult>();

    // Scrape all URLs in parallel with concurrency limit of 3
    // (Firecrawl Hobby plan has 5 concurrent browsers)
    const CONCURRENCY = 3;
    const chunks = this.chunkArray(options.urls, CONCURRENCY);

    for (const chunk of chunks) {
      const chunkResults = await Promise.all(
        chunk.map(url => this.scrape({ url, timeout }))
      );

      for (let i = 0; i < chunk.length; i++) {
        results.set(chunk[i], chunkResults[i]);
      }
    }

    const successCount = Array.from(results.values()).filter(r => r.success).length;

    return {
      results,
      successCount,
      failureCount: options.urls.length - successCount,
    };
  }

  /**
   * Normalize a website URL to ensure consistent base URL format
   */
  private normalizeBaseUrl(url: string): string {
    // Add protocol if missing
    let normalized = url.startsWith('http') ? url : `https://${url}`;

    // Remove trailing slash
    normalized = normalized.replace(/\/+$/, '');

    // Remove any path (we want just the base)
    try {
      const parsed = new URL(normalized);
      return `${parsed.protocol}//${parsed.host}`;
    } catch {
      // If URL parsing fails, return as-is
      return normalized;
    }
  }

  /**
   * Split array into chunks for controlled concurrency
   */
  private chunkArray<T>(array: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
}

/**
 * Factory function to create a FirecrawlClient instance
 *
 * Usage:
 * ```typescript
 * const client = createFirecrawlClient();
 * if (client.isAvailable()) {
 *   const result = await client.scrapePricingPage('https://example.com');
 * }
 * ```
 */
export function createFirecrawlClient(): FirecrawlClient {
  return new FirecrawlClient();
}
```

Key implementation decisions:
- Uses `getEnv` (not `getRequiredEnv`) for optional API key
- Graceful degradation: returns failure result, never throws
- 30s timeout default (matches research recommendation)
- Hardcoded paths: /pricing, /plans, /buy (from CONTEXT.md decisions)
- 3 concurrent requests (leaves headroom for Hobby plan's 5 browser limit)
- Low word count warning at <100 words (potential JS rendering issue)
  </action>
  <verify>
- `npm run lint` passes
- `npm run build` passes
- TypeScript compiles without errors
  </verify>
  <done>
- FIRECRAWL_API_KEY added to OPTIONAL_ENV_VARS in env.ts
- FirecrawlClient class with scrape, scrapePricingPage, batchScrape methods
- Graceful degradation when API key is missing
  </done>
</task>

<task type="auto">
  <name>Task 3: Create barrel export and verify integration</name>
  <files>src/lib/firecrawl/index.ts</files>
  <action>
1. Create `src/lib/firecrawl/index.ts`:

```typescript
// Firecrawl Module
// Web scraping with JavaScript rendering via Firecrawl SDK

export { FirecrawlClient, createFirecrawlClient } from './client';
export type {
  ScrapeOptions,
  ScrapeResult,
  PricingPageResult,
  BatchScrapeOptions,
  BatchScrapeResult,
} from './types';
```

2. Verify the module imports correctly by checking:
   - Import from `@/lib/firecrawl` works
   - All types are exported
   - Build passes

3. Test graceful degradation (manual verification in dev):
   - Without FIRECRAWL_API_KEY set, createFirecrawlClient().isAvailable() returns false
   - scrape() and scrapePricingPage() return failure results without throwing
  </action>
  <verify>
- `npm run build` passes
- `npm run lint` passes
- Import test: Create a simple test file or verify in REPL that `import { createFirecrawlClient } from '@/lib/firecrawl'` works
  </verify>
  <done>
- src/lib/firecrawl/index.ts exists with all exports
- Module can be imported from @/lib/firecrawl
- Build and lint pass
  </done>
</task>

</tasks>

<verification>
Overall verification after all tasks complete:

1. **Build passes:** `npm run build` completes without errors
2. **Lint passes:** `npm run lint` shows no errors
3. **Type check:** `npx tsc --noEmit` passes
4. **Package installed:** `@mendable/firecrawl-js` in package.json
5. **Graceful degradation:** Without FIRECRAWL_API_KEY:
   - `createFirecrawlClient().isAvailable()` returns `false`
   - `scrape()` returns `{ success: false, error: '...' }`
   - No exceptions thrown
</verification>

<success_criteria>
1. FirecrawlClient wraps SDK with AI-GOS error handling patterns
2. Pricing page discovery tries /pricing, /plans, /buy fallback URLs
3. Scraping errors are logged and handled gracefully without crashing pipeline
4. Missing FIRECRAWL_API_KEY allows pipeline to continue without Firecrawl
5. All files created: types.ts, client.ts, index.ts
6. FIRECRAWL_API_KEY added to optional env vars
</success_criteria>

<output>
After completion, create `.planning/phases/35-firecrawl-foundation/35-01-SUMMARY.md` following the summary template.

Include in the summary:
- Files created and their exports
- Key decisions made (timeout values, concurrency limits, path order)
- How to use the client (code example)
- What Phase 36 needs to know (client.scrapePricingPage returns markdown for LLM extraction)
</output>
